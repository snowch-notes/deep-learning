{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Loss Function Optimization with the Chain Rule\n",
    "\n",
    "This notebook visually demonstrates the concepts from the StatQuest video on the Chain Rule, specifically from the **11:30** mark onwards. We'll explore how to find the optimal **intercept** for a simple line to minimize the **squared residual** (our loss function) for a single data point.\n",
    "\n",
    "### The Goal ðŸŽ¯\n",
    "\n",
    "Given a single data point and a line with a fixed slope, we want to find the `intercept` that makes the line fit the point as closely as possible. We measure \"closeness\" using the **squared residual**.\n",
    "\n",
    "1.  **Model:** `predicted_height = intercept + 1 * weight`\n",
    "2.  **Loss Function:** `squared_residual = (observed_height - predicted_height)^2`\n",
    "\n",
    "We will find the minimum of this loss function by finding where its derivative with respect to the intercept is equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a professional and clean style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Data and The Model\n",
    "\n",
    "First, let's define our single observed data point, as shown in the video. We have a person's weight and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The single data point from the video\n",
    "observed_weight = 3\n",
    "observed_height = 4\n",
    "\n",
    "# Our model is a line with a fixed slope of 1\n",
    "# predicted_height = intercept + 1 * weight\n",
    "def predict_height(intercept, weight):\n",
    "    return intercept + 1 * weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how different intercepts affect the line's fit to our data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the observed data point\n",
    "plt.plot(observed_weight, observed_height, 'ro', markersize=10, label='Observed Data Point (3, 4)')\n",
    "\n",
    "# Define a range of weights for plotting the lines\n",
    "weights = np.linspace(0, 5, 100)\n",
    "\n",
    "# Plot lines with different intercepts\n",
    "for intercept_val in [-1, 0, 1, 2]:\n",
    "    heights = predict_height(intercept_val, weights)\n",
    "    plt.plot(weights, heights, '--', label=f'Intercept = {intercept_val}')\n",
    "\n",
    "# Show the residual for the intercept = 0 case\n",
    "predicted_for_intercept_0 = predict_height(0, observed_weight)\n",
    "plt.vlines(observed_weight, ymin=predicted_for_intercept_0, ymax=observed_height, \n",
    "           colors='gray', linestyles='solid', lw=2, label='Residual for Intercept = 0')\n",
    "plt.text(3.1, 3.5, 'Residual',\n",
    "         verticalalignment='center', color='gray')\n",
    "\n",
    "plt.title('Fitting a Line to a Single Data Point', fontsize=16)\n",
    "plt.xlabel('Weight', fontsize=12)\n",
    "plt.ylabel('Height', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlim(0, 5)\n",
    "plt.ylim(0, 6)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing The Loss Function\n",
    "\n",
    "The **loss function** tells us how \"bad\" our model is for a given intercept. We are using the **squared residual**. Let's calculate and plot the squared residual for a wide range of possible intercepts. The resulting curve is our \"loss curve\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of possible intercept values to test\n",
    "intercepts = np.linspace(-2, 4, 200)\n",
    "\n",
    "# Calculate the squared residual for each intercept\n",
    "predicted_heights = predict_height(intercepts, observed_weight)\n",
    "residuals = observed_height - predicted_heights\n",
    "squared_residuals = residuals**2 # This is our loss\n",
    "\n",
    "# Find the intercept that gives the minimum loss from our samples\n",
    "min_loss_intercept = intercepts[np.argmin(squared_residuals)]\n",
    "min_loss_value = np.min(squared_residuals)\n",
    "\n",
    "# Plot the loss curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(intercepts, squared_residuals, 'b-', label='Loss (Squared Residual)')\n",
    "plt.plot(min_loss_intercept, min_loss_value, 'go', markersize=10, label=f'Minimum Loss at Intercept â‰ˆ {min_loss_intercept:.2f}')\n",
    "\n",
    "plt.title('Loss Function vs. Intercept', fontsize=16)\n",
    "plt.xlabel('Intercept Value', fontsize=12)\n",
    "plt.ylabel('Squared Residual (Loss)', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, we can see the loss is minimized when the **intercept is 1.0**. Now, let's prove this with calculus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding the Minimum with Calculus\n",
    "\n",
    "As explained in the video, we can use the **chain rule** to find the derivative of the squared residual with respect to the intercept.\n",
    "\n",
    "Let $L$ be the loss (squared residual) and $b$ be the intercept.\n",
    "\n",
    "$$ L = (y_{obs} - y_{pred})^2 = (y_{obs} - (b + w_{obs}))^2 $$\n",
    "\n",
    "The derivative, $\\frac{dL}{db}$, tells us the slope of the loss curve. The minimum of the curve is where the slope is zero. Using the chain rule, the derivative is:\n",
    "\n",
    "$$ \\frac{dL}{db} = 2 \\cdot (y_{obs} - (b + w_{obs})) \\cdot (-1) = -2(y_{obs} - b - w_{obs}) $$\n",
    "\n",
    "Let's plot this derivative and see where it crosses zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the derivative function\n",
    "def derivative_loss(intercept, obs_h, obs_w):\n",
    "    return -2 * (obs_h - intercept - obs_w)\n",
    "\n",
    "# Calculate the derivative for our range of intercepts\n",
    "derivatives = derivative_loss(intercepts, observed_height, observed_weight)\n",
    "\n",
    "# Plot the derivative\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(intercepts, derivatives, 'm-', label='Derivative of Loss')\n",
    "plt.axhline(0, color='black', linestyle='--', label='Slope = 0')\n",
    "\n",
    "# Find where the derivative is closest to zero\n",
    "zero_crossing_intercept = intercepts[np.argmin(np.abs(derivatives))]\n",
    "plt.plot(zero_crossing_intercept, 0, 'go', markersize=10, label=f'Derivative is 0 at Intercept â‰ˆ {zero_crossing_intercept:.2f}')\n",
    "\n",
    "plt.title('Derivative of the Loss Function', fontsize=16)\n",
    "plt.xlabel('Intercept Value', fontsize=12)\n",
    "plt.ylabel('Derivative (Slope of Loss Curve)', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot confirms that the derivative is zero when the **intercept is 1.0**. This is the location of the minimum of our loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Solution: The Best-Fit Line\n",
    "\n",
    "Now we can solve for the intercept analytically by setting the derivative to 0:\n",
    "\n",
    "$$ -2(y_{obs} - b - w_{obs}) = 0 $$\n",
    "$$ y_{obs} - b - w_{obs} = 0 $$\n",
    "$$ b = y_{obs} - w_{obs} $$\n",
    "\n",
    "Let's calculate the exact optimal intercept and plot the final, best-fitting line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytically solve for the best intercept\n",
    "optimal_intercept = observed_height - observed_weight\n",
    "print(f\"The optimal intercept is: {optimal_intercept}\")\n",
    "\n",
    "# Plot the final result\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the observed data point\n",
    "plt.plot(observed_weight, observed_height, 'ro', markersize=10, label='Observed Data Point (3, 4)')\n",
    "\n",
    "# Plot the best-fit line\n",
    "heights = predict_height(optimal_intercept, weights)\n",
    "plt.plot(weights, heights, 'g-', lw=3, label=f'Best-Fit Line (Intercept = {optimal_intercept})')\n",
    "\n",
    "plt.title('Optimal Line Fit by Minimizing Squared Residual', fontsize=16)\n",
    "plt.xlabel('Weight', fontsize=12)\n",
    "plt.ylabel('Height', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlim(0, 5)\n",
    "plt.ylim(0, 6)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion âœ…\n",
    "\n",
    "We have successfully used the principles of calculus, specifically the chain rule, to find the derivative of our loss function. By setting this derivative to zero, we found the exact intercept value that **minimizes the squared residual**, giving us the best possible fit for our simple model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
