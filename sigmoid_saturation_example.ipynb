{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3c60b9",
   "metadata": {},
   "source": [
    "# Neural Network Saturation with Sigmoid Activation\n",
    "This notebook demonstrates how large initial weights in a neural network using sigmoid activation can cause training to stall due to saturation, and provides a fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# XOR inputs\n",
    "X = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "# XOR outputs\n",
    "y = np.array([\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Visualize sigmoid and its gradient\n",
    "x_vals = np.linspace(-10, 10, 500)\n",
    "sig_vals = sigmoid(x_vals)\n",
    "grad_vals = sigmoid_derivative(x_vals)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_vals, sig_vals, label=\"sigmoid(x)\", color=\"blue\")\n",
    "plt.title(\"Sigmoid Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"sigmoid(x)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_vals, grad_vals, label=\"sigmoid'(x)\", color=\"red\")\n",
    "plt.title(\"Sigmoid Gradient\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"sigmoid'(x)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network with large initial weights â€” will stall\n",
    "\n",
    "np.random.seed(0)\n",
    "W1 = np.random.randn(2, 4) * 10\n",
    "b1 = np.zeros((1, 4))\n",
    "W2 = np.random.randn(4, 1) * 10\n",
    "b2 = np.zeros((1, 1))\n",
    "\n",
    "lr = 0.1\n",
    "epochs = 5000\n",
    "\n",
    "print(\"ðŸš« Training with saturated sigmoid (large weights):\")\n",
    "for epoch in range(epochs):\n",
    "    Z1 = X @ W1 + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = A1 @ W2 + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    loss = np.mean((y - A2) ** 2)\n",
    "\n",
    "    dA2 = -(y - A2)\n",
    "    dZ2 = dA2 * sigmoid_derivative(Z2)\n",
    "    dW2 = A1.T @ dZ2\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    dA1 = dZ2 @ W2.T\n",
    "    dZ1 = dA1 * sigmoid_derivative(Z1)\n",
    "    dW1 = X.T @ dZ1\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1\n",
    "    W2 -= lr * dW2\n",
    "    b2 -= lr * db2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d1bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Fixed version: small weight init + optional BCE loss\n",
    "\n",
    "np.random.seed(0)\n",
    "W1 = np.random.randn(2, 4) * 0.1\n",
    "b1 = np.zeros((1, 4))\n",
    "W2 = np.random.randn(4, 1) * 0.1\n",
    "b2 = np.zeros((1, 1))\n",
    "\n",
    "lr = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "print(\"\\nâœ… Training with small weights and BCE loss:\")\n",
    "for epoch in range(epochs):\n",
    "    Z1 = X @ W1 + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = A1 @ W2 + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    eps = 1e-8\n",
    "    loss = -np.mean(y * np.log(A2 + eps) + (1 - y) * np.log(1 - A2 + eps))\n",
    "\n",
    "    dA2 = -(y / (A2 + eps)) + ((1 - y) / (1 - A2 + eps))\n",
    "    dZ2 = dA2 * sigmoid_derivative(Z2)\n",
    "    dW2 = A1.T @ dZ2\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    dA1 = dZ2 @ W2.T\n",
    "    dZ1 = dA1 * sigmoid_derivative(Z1)\n",
    "    dW1 = X.T @ dZ1\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1\n",
    "    W2 -= lr * dW2\n",
    "    b2 -= lr * db2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.6f}\")\n",
    "\n",
    "preds = A2.round()\n",
    "print(\"\\nPredictions:\\n\", preds)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
